<!doctype html>
<html lang="en">
<head>
<title>David Bau: Interpretable Deep Networks</title>
<meta name="description" content="Specializing in the analysis and control of the internal computations of deep generative models for images and text, David Bau is a leading researcher in interpretable deep network methods.">
<link rel="canonical" href="https://baulab.info/">
<meta name="viewport" content="width=device-width,initial-scale=1.0">
<link href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-rwoIResjU2yc3z8GV/NPeZWAv56rSmLldC3R/AZzGRnGxQQKnKkoFVhFQhNUwEyJ" crossorigin="anonymous">
<script src="https://code.jquery.com/jquery-3.2.1.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tether/1.4.0/js/tether.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/js/bootstrap.min.js" integrity="sha384-vBWWzlZJ8ea9aCX4pEW3rVHjgjt7zpkNpZk+02D9phzyeVkE+jo0ieGizqPLForn" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700" rel="stylesheet">
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<style>
body, td, th {
  font-family: 'Open Sans', sans-serif;
  background-color: #e4f1fe;
}
.prologue {
  margin-bottom: 1rem;
}
span.me {
  font-weight: bold;
  white-space: nowrap;
}
h1, h2, h3, h4, h5, h6 {
  font-weight: 300;
  text-align: center;
}
input.collapse {
  display: none;
}
h2, .namecard {
  background-color: #0E2863;
  color: #e4f1fe;
  position: relative;
  padding: 30px;
  box-shadow: 0 1px 3px rgba(0,0,0,0.12), 0 1px 2px rgba(0,0,0,0.24);
}
::cue {
  font-family: 'Open Sans', sans-serif;
  font-size: 15px;
  color: #FFF;
}
.people {
  text-align: justify;
  text-align-last: justify;
}
.people a img {
  width: 120px;
}
.people a[href] {
  display: inline-block;
  width: 132px;
  padding: 4px;
  text-align: center;
  text-align-last: center;
  vertical-align: top;
}
.collapse + p, .prologue {
  background-color: white;
  position: relative;
  padding: 30px;
  box-shadow: 0 1px 3px rgba(0,0,0,0.12), 0 1px 2px rgba(0,0,0,0.24);
  transition: all 0.3s cubic-bezier(.25,.8,.25,1);
}
.collapse + p:hover {
  box-shadow: 0 14px 28px rgba(0,0,0,0.25), 0 10px 10px rgba(0,0,0,0.22);
  cursor: default;
}
.collapse + p .more::before {
  content: 'more\25B9';
  padding-right: .2em;
  color: #0275d8;
  cursor: pointer;
  transition: font-size 0.2s;
}
.collapse + p:hover .more::before {
  color: seagreen;
}
.collapse:checked + p .more::before {
  content: '\25C3';
  color: lightgray;
  position: absolute;
  font-style: normal;
  right: 3px;
  bottom: 0;
}
.collapse + p .more:hover::before {
  color: lightseagreen;
}
.collapse + p .extra {
  font-size: 0;
  opacity: 0;
  transition: opacity 0.5s, font-size 0.2s;
}
.collapse + p .extra img {
  height: 0;
  transition: height 0.2s;
}
.collapse:checked + p .extra {
  font-size: 16px;
  opacity: 1;
}
.collapse + p::after {
  content: '';
  display: block;
  clear: both;
  padding: 0;
  margin: 0;
}
.footer {
  margin-top: 8px;
  text-align: justify;
  /*word-spacing: 10px; */
  width: 100%;
}
.footer::after {
  content: '';
  width: 100%;
  display: inline-block;
}
.footer a {
  word-spacing: initial;
  display: inline-block;
}
.namecard {
  padding: 2rem 15px 1rem;
  text-align: center;
  font-weight: 300;
}
.namecard a {
  color: inherit;
}
.namecard h1 {
  font-size: 2.5rem;
  font-weight: 300;
  color: inherit;
}
.selfpic {
  width: 448px;
  max-width: 100%;
  display: block;
  height: auto;
}
.selfpic iframe {
  max-width: 100%;
}
.projpic {
  width: 288px;
  max-width: 100%;
  display: block;
  margin: 0 auto 15px auto;
}
figcaption {
  display: block;
  text-align: center;
  font-size: 12px;
  margin-top: 3px;
}
.highlight {
  padding: 1.5rem;
  margin-right: 0;
  margin-left: 0;
  background: gainsboro;
}
@media (min-width: 576px) {
  .nd-pageheader {
    padding-top:1rem;
    padding-bottom: 1rem;
  }
}
@media (min-width: 768px) {
  .nd-pageheader h1 {
    font-size:3rem
  }
  .nd-pageheader p {
    font-size: 1.5rem
  }
  .selfpic {
    display: inline-block;
  }
  .projpic {
    float: left;
    margin: 0 1rem 0 0;
  }
}
@media (min-width: 992px) {
  .people a[href] {
    margin: 0 2px;
  }
}
@media (min-width: 1200px) {
  .people a[href] {
    margin: 0 10px;
  }
}
</style>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-FD12LWN557"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date()); gtag('config', 'G-FD12LWN557');
</script>
</head>
<body class="db-page">
<div class="container">
<div class="row">
<div class="col">
 <div class="namecard">
 <h1><nobr>David Bau</nobr></h1>
 <p class="lead">
 <nobr>Interpretable Neural Networks</nobr>
<address>
 <a href="https://www.khoury.northeastern.edu/research/">
 <nobr>Northeastern University </nobr>
 <nobr>Khoury College of Computer Sciences</nobr></a><br>
 <!-- <nobr>Massachusetts Institute of Technology</nobr><br> -->
 <nobr><script>
var emn = 'davidbau' + ''.constructor.fromCharCode(1<<6) + 'northeastern.edu';
document.write('<a href="mailto:' + emn + '">' + emn + '</a>');
 </script></nobr><br>
</address>
 </p>
 </div>
<div class="prologue clearfix">
<figure class="float-right ml-3 selfpic">
<!--<img src="family.jpg" class="selfpic">
<figcaption>David Bau (center) and family:<br>(clockwise) Heidi, Cody, Piper, and Anthony</figcaption>-->
<!--<iframe id="selfpic-video" width="448" height="252"
src="https://www.youtube.com/embed/jT5nYLND7co?controls=1&playsinline=1&loop=1&modestbranding=1&rel=0&cc_load_policy=1&enablejsapi=1&origin=http://baulab.info/"
frameborder="0" allow="accelerometer;encrypted-media;gyroscope;picture-in-picture" allowfullscreen></iframe>-->
<!--
<video controls width="448" height="252" poster="video-poster.png" preload="metadata"
  class="selfpic">
<source src="understanding-video-compact.mp4" type="video/mp4" />
<track default kind="captions" srclang="en" label="English Captions"
 src="understanding-video-english.vtt" />
</video>
<figcaption>Why we study deep network internals.  <nobr>David Bau</nobr> (narrates), with Antonio Torralba, Jun-Yan Zhu, Hendrik Strobelt, Jonas Wulff, and William Peebles. <nobr>Video by Lillie Paquette,</nobr> MIT School of Engineering.</figcaption>
-->
<a href="/video.html"><img width="448" height="252" src="video-poster.png" class="selfpic"></a>
<figcaption>A brief interview with David: why we study deep network internals.</figcaption>
</figure>

<p>
I am an Assistant Professor of Computer Science at <a
href="https://www.khoury.northeastern.edu/research/research-areas/"
>Northeastern Khoury College</a>. My lab studies the structure
and interpretation of deep networks.
<p>
We think that understanding the rich internal structure of deep
networks is a grand and fundamental research question with many
practical implications.
</p>
<p>
We aim to lay the groundwork for human-AI collaborative
software engineering, where humans and machine-learned
models both teach and learn from each other.
<p>
Want to come to Boston to work on deep learning with me?
<a href="https://www.khoury.northeastern.edu/apply/phd-apply/">Apply
  to Khoury here</a> and <a href="students.html"
  >contact me</a> if you are interested in joining as a graduate
student or postdoc.
Also check out <a href="https://ndif.us/fellowship.html">NDIF engineering fellowships</a>.


<p>
<a href="publications.html">Publication List</a>. (PNAS; NeurIPS; ICLR; TPAMI; CVPR; SIGGRAPH; ECCV; ICCV.)
<br>
<a href="cv.html">Curriculum Vitae</a>.
(PhD MIT EECS, <a href="http://dissection.csail.mit.edu/">thesis</a>; Cornell; Harvard; Google; Microsoft. <a href="https://sloan.org/fellowships/2025-fellows">Sloan fellowship</a>, <a href="https://www.khoury.northeastern.edu/awards/">Spira teaching award</a>)
<br>
Publication pages on
<a href="http://dblp.uni-trier.de/pers/hd/b/Bau:David">Dblp</a>
and <a href="https://scholar.google.com/citations?hl=en&user=CYI6cKgAAAAJ&view_op=list_works&sortby=pubdate">Google Scholar</a>.

<p>
<a href="https://talks.baulab.info/">Talks at the Bau Lab</a> ;
<a href="https://resilience.baulab.info/">What is AI interpretability for?</a>
<!--
My office at MIT:
<a href="https://whereis.mit.edu/?zoom=16&lat=42.361612839999985&lng=-71.09056785999995&maptype=mit&q=32-383&open=object-32">Stata 32-383</a>
-->
</div> <!-- prologue -->
</div>
</div>


<div class="row">
<div class="col">
<div class="publication">
<h2 class="mt-4 mb-3">Lab Members</h2>
<input class="collapse" type="checkbox">
<p class="people">
<span class="current">
<a href="https://canrager.notion.site/">
<img src="people/can.jpg">
Can Rager
</a>
<a href="https://scholar.google.co.il/citations?hl=en&user=hd7quH4AAAAJ&sortby=pubdate">
<img src="people/natalie.jpg">
Natalie Shapira
</a>
<a href="https://wendlerc.github.io/">
<img src="people/chris.jpg">
Chris Wendler
</a>
<a href="https://github.com/diatkinson">
<img src="people/davidatkinson.jpg">
David Atkinson
</a>
<a href="https://sfeucht.github.io/">
<img src="people/sheridan.jpg">
Sheridan Feucht
</a>
<!--
<a href="https://www.linkedin.com/in/arthur-conmy-a029211a8/">
<img src="people/arthur.jpg">
Arthur Conmy
</a>
-->
<a href="https://rohitgandikota.github.io/">
<img src="people/rohit.jpg">
Rohit Gandikota
</a>
<a href="https://arnab-api.github.io/">
<img src="people/arnab.jpg">
Arnab Sen Sharma
</a>
<a href="https://ericwtodd.github.io/">
<img src="people/eric.jpg">
Eric Todd
</a>
<a href="https://koyenapal.github.io/">
<img src="people/koyena.jpg">
Koyena Pal
</a>
<a href="https://nix07.github.io/">
<img src="people/nikhil.jpg">
Nikhil Prakash
</a>
<a href="https://github.com/JadenFiotto-Kaufman">
<img src="people/jaden.jpg">
Jaden Fiotto-Kaufman
</a>
<a href="https://alex-loftus.com/">
<img src="people/loftus.jpg">
Alex Loftus
</a>
</span>
<span class="extra">
<a href="https://aaronmueller.github.io/">
<img src="people/aaron.jpg">
Aaron Mueller
</a>
<a href="https://www.lesswrong.com/users/sam-marks">
<img src="people/sam.jpg">
Sam Marks
</a>
</span>
<!--
<a href="https://mengk.me/">
<img src="people/kevin.jpg">
Kevin Meng
</a>
-->
</p>
</div>
</div>
</div>
<script>
var p = document.querySelector('p.people .current');
for (var i = p.children.length; i >= 0; i--) {
   p.appendChild(p.children[Math.random() * i | 0]);
   p.appendChild(document.createTextNode('\n'));
}
</script>
<!--
<div class="row">
<div class="col">
<div class="publication">
<h2 class="mt-4 mb-3">Current Collaborations</h2>
<input class="collapse" type="checkbox">
<p class="people">
<a href="https://audreycui.github.io/">
<img src="people/audrey.jpg">
Audrey Cui
</a>
<a href="https://mengk.me/">
<img src="people/kevin.jpg">
Kevin Meng
</a>
<a href="https://joaanna.github.io/">
<img src="people/joanna.jpg">
Joanna Materzynska
</a>
<a href="https://peterwang512.github.io/">
<img src="people/shengyu.jpg">
Sheng-Yu Wang
</a>
<a href="https://evandez.com/">
<img src="people/evan.jpg">
Evan Hernandez
</a>
<a href="https://dblp.org/pid/236/5817.html">
<img src="people/nadiia.jpg">
Nadiia Chepurko
</a>
<a href="https://www.alexandonian.com/">
<img src="people/alex.jpg">
Alex Andonian
</a>
<a href="http://people.fas.harvard.edu/~spm253/spandan/index.html">
<img src="people/spandan.jpg">
Spandan Madan
</a>
<a href="https://skitree.github.io/aspenhopkins/">
<img src="people/aspen.jpg">
Aspen Hopkins
</a>
<a href="https://likenneth.github.io/">
<img src="people/kenneth.jpg">
Kenneth Li
</a>
<a href="http://angieboggust.com/">
<img src="people/angie.jpg">
Angie Boggust
</a>
<a href="https://dtsipras.com/">
<img src="people/dimitris.jpg">
Dimitris Tsipras
</a>
<a href="https://shibanisanturkar.com/">
<img src="people/shibani.jpg">
Shibani Santurkar
</a>
<a href="https://people.csail.mit.edu/jahanian/">
<img src="people/ali.jpg">
Ali Jahanian
</a>
<a href="http://www.cogconfluence.com/">
<img src="people/sarah.jpg">
Sarah Schwettman
</a>
<a href="http://hendrik.strobelt.com/">
<img src="people/hen.jpg">
Hendrik Strobelt
</a>
<a href="students.html">
<img src="people/icon.png">
Information for Applicants
</a>
<a href="https://groups.csail.mit.edu/vision/torralbalab/">
<img src="people/antonio.jpg">
Prof. Antonio Torralba
</a>
<a href="http://www.bewitched.com/">
<img src="people/martin.jpg">
Prof. Martin Wattenberg
</a>
<a href="https://www.cs.technion.ac.il/~belinkov/">
<img src="people/yonatan.jpg">
Prof. Yonatan Belinkov
</a>
<a href="https://www.cs.cmu.edu/~junyanz/">
<img src="people/junyan.jpg">
Prof. Jun-Yan Zhu
</a>
<a href="https://www.eng.ufl.edu/eed/faculty-staff/jeremiah-blanchard/">
<img src="people/jeremiah.jpg">
Prof. Jeremiah Blanchard
</a>
<a href="https://www.mit.edu/~jda/">
<img src="people/jacob.jpg">
Prof. Jacob Andreas
</a>
<a href="http://olivalab.mit.edu/audeoliva.html">
<img src="people/aude.jpg">
Prof. Aude Oliva
</a>
<a href="https://people.csail.mit.edu/madry/">
<img src="people/madry.jpg">
Prof. Aleksander Madry
</a>
<a href="http://sunai.uoc.edu/~agata/">
<img src="people/agata.jpg">
Prof. Agata Lapedriza
</a>
<a href="https://vcg.seas.harvard.edu/people">
<img src="people/hp.jpg">
Prof. Hanspeter Pfister
</a>
<a href="https://arvindsatya.com/">
<img src="people/arvind.jpg">
Prof. Arvind Satyanarayan
</a>
</div>
</div>
</div>
-->

<div class="row">
<div class="col">
<div class="publication">
<h2 class="mt-4 mb-3">In the News</h2>


<input class="collapse" type="checkbox">
<p>
   <img src="botas-blackbox.png" class="projpic"
   ><a href="https://thebulletin.org/2025/01/why-nobody-can-see-inside-ais-black-box/"
   >Why nobody can see inside AI's black box</a>
   "People can have a variety of motivations for understanding internals...
   I'm motivated by transparency because we have responsibility for the
   systems we make..."
   <span class="more"></span>
   <span class="extra">
     At the most fundamental level, the tech companies building these AI
     systems don't fully understand how their models work internally&mdash;a
     challenge inherent to the technology itself. But there's a second,
     distinct barrier to transparency: Developers aren't making the data
     they train these systems with available to those outside their
     organizations...
     Grasping the fundamental internals of AI models is important
     because it could enable precise interventions when needed...
     With access to AI system's training data and methods and the
     computing resources needed to independently study these systems,
     academic researchers could help fill this knowledge gap.
   </span>
   <a href="https://thebulletin.org/2025/01/why-nobody-can-see-inside-ais-black-box/"
   ><strong>Bulletin of the Atomic Scientists</strong> by Abi Olvera, January 27, 2025.</a>
</p>

<input class="collapse" type="checkbox">
<p>
   <img src="nature-think.jpg" class="projpic"
   ><a href="https://www.nature.com/articles/d41586-024-01314-y"
   >How does ChatGPT think?</a>
   "Researchers are striving to reverse-engineer artificial intelligence
   and scan the 'brains' of LLMs to see what they are doing, how and why...
   <span class="more"></span>
   <span class="extra">
     Researchers want explanations so that they can create safer, more
     efficient and more accurate AI. Users want explanations so that they
     know when to trust a chatbot's output. And regulators want explanations
     so that they know what AI guard rails to put in place....
     Bau and his colleagues have also developed methods
     to scan and edit AI neural networks, including a technique they call
     <a href="https://rome.baulab.info">causal tracing</a>...."
     This news article in Nature surveys the emerging field of
     deep network interpretation. The increasing complexity of generative
     AI systems such as ChatGPT has spawned a new research subfield
     that cracks open these large models and interprets their
     emergent internal structure. The article surveys
     perspectives on this new research area from several
     relevant researchers including
     <a href="https://baulab.info/">David Bau</a>,
     <a href="https://mega002.github.io/">Mor Geva</a>,
     <a href="https://www.bewitched.com/">Martin Wattenberg</a>,
     <a href="https://colah.github.io/about.html">Chris Olah</a>,
     <a href="https://www.thilo-hagendorff.info/">Thilo Hagendorff</a>,
     <a href="https://cims.nyu.edu/~sbowman/">Sam Bowman</a>,
     <a href="https://www.oii.ox.ac.uk/people/profiles/sandra-wachter/">Sandra Wachter</a>,
     <a href="https://andyzoujm.github.io/">Andy Zou</a>, and
     <a href="https://peterbhase.github.io/">Peter Hase</a>.
     The article also highlights research from
     <a href="https://likenneth.github.io/">Kenneth Li</a>,
     <a href="https://www.jasonwei.net/">Jason Wei</a>,
     <a href="https://www.milesturp.in/about/">Miles Turpin</a>,
     <a href="https://mengk.me/">Kevin Meng</a> and
     <a href="https://www.cs.toronto.edu/~rgrosse/">Roger Grosse</a>.
   </span>
   <a href="https://www.nature.com/articles/d41586-024-01314-y"
   ><strong>Nature</strong> news feature by Matthew Hutson, May 14, 2024.</a>
</p>

<input class="collapse" type="checkbox">
<p>
   <img src="ndif-textlogo.png" class="projpic">
   We have launched the
   <a href="https://ndif.us/">National Deep Inference Fabric (NDIF)</a>
   project.
   <span class="more"></span>
   <span class="extra">
   Large-scale AI presents fundamental open scientific
   questions and major societal impacts that are not yet well-understood&mdash;and
   they are both difficult and expensive to study. <a href="https://ndif.us/">NDIF</a>
   is a major investment in scientific infrastructure to help meet
   the challenge, with $9m of funding from the National Science Foundation
   to develop large-scale AI inference software aimed
   at enabling cutting-edge research.  Questions in the public interest,
   such as "how can we explain an AI decision?"
   or "what can improve the safety and robustness of AI?"
   The goal of NDIF is to provide a robust and transparent AI inference
   service to enable scientists in every part of the country in every
   field touched by AI, to expand, accelerate, and democratize impactful
   AI science. (Programmers interested in the technical details can
   <a href="https://pypi.org/project/nnsight/">pip install nnsight</a>
   to try NDIF today.)  Users can remotely access and alter activations,
   gradients, and customize any step of
   <a href="https://nnsight.net/status">large models like llama3-70b</a>
   like having a 70b model on your own laptop. This transparency
   goes far behyond commercial AI inference services, and
   NSF funding will expand NDIF to support every
   open model and a broad range of research methods.
   Read about the positions NDIF is hiring to fill on 
   <a href="https://www.linkedin.com/feed/update/urn:li:activity:7197729186701004800/">LinkedIn</a>,
   <a href="https://x.com/davidbau/status/1787597395741835564">Twitter/X</a>, and
   on the <a href="https://ndif.us/">NDIF website</a>.
   </span>
   <a href="https://news.northeastern.edu/2024/05/02/nsf-funds-democratizing-ai-research/"
   >NSF funds groundbreaking research led by Northeastern to democratize artificial intelligence.
   Northeastern Global News, May 2, 2024.</a>
</p>
</div>
</div>
</div>


<div class="row">
<div class="col">
<div class="publication">
<h2 class="mt-4 mb-3">Selected Projects</h2>

<input class="collapse" type="checkbox">
<p>
<img src="sliders.png" class="projpic">
<a href="http://sliders.baulab.info/">Concept Sliders.</a>
 While GANs are famous for containing disenangled latents that can control a variety
 of interpretable image attributes, it has not been known whether similar controllable
 latents are present in diffusion models.
 In this work, we develop Concept Sliders, a way of finding
 LoRA adjustments to diffusion model weights that cleanly and smoothly
 control a single disentangled concept.  With Concept Sliders, an
 artist can easily modulate a single attribute like "age" or
 "smiling" or even "cooked food" to smoothly adjust the visual
 characteristics of an image.
<span class="more"></span>
<span class="extra">
 Concept sliders are based on the guided-training technique underling
 our previous <a href="https://erasing.baulab.info">ESD</a> work, but
 instead of erasing a concept, we develop the needed techniques to
 modulate or amplify a concept without changing the underlying layout
 of the image, and without entangling the concept with correlated
 concepts that we wish to remain unchanged.  Concept sliders have been
 an open-source hit among the artistic community, and they also provide
 a promising window into the organization of visual concept information
 within the parameter space of diffusion models.  The paper develops
 and evaluates over 50 different concept sliders including very interesting
 sliders that reduce visible distortions in diffusion model output, and
 examines their efficacy, specificity, and composability.
</span>
<a href="https://arxiv.org/abs/2311.12092"
   >R Gandikota, J Materzy&nacute;ska, T Zhou, A Torralba,
   <span class="me">D Bau</span>.
   <em>Concept Sliders: LoRA Adaptors for Precise Control in Diffusion Models</em>
   <nobr>ECCV 2024.</nobr></a>
</p>

<input class="collapse" type="checkbox">
<p>
<img src="lre.png" class="projpic">
<a href="http://lre.baulab.info/">Linearity of Relation Decoding in Transformer LMs.</a>
 What is the right level of abstraction to use when understanding a huge network?
 While it is natural to examine individual neurons, attention heads, modules, and
 representation vectors, we should also ask whether taking a holistic view of
 a larger part of the network can reveal any higher-level structure. In this work,
 we ask how relationships between entities and their attributes are represented,
 and we measure the power of the <em>Jacobian</em>&mdash;the matrix derivative&mdash;to
 capture the action of a range of transformer layers in applying a relation to an entity.
<span class="more"></span>
<span class="extra">
 When a representation vector passes through a range of transformer layers, it
 is subjected to a very nonlinear transformation. Yet in this paper we find that
 when the network resolves a specific relationship such as
 <em>person X plays instrument Y</em>, the action of the transformer from the vector
 for X to the vector for Y will often be essentially linear, suggesting
 that the information about Y is already present in X. Moreover the linear operator
 can be extracted by examining the Jacobian using as few as a single example of
 the relation.  We analyze more than 40 different relations to determine which
 have a linear representation, and we introduce a tool, the <em>attribute lens</em>
 that exploits linearity to visualize the relational information carried in a
 state vector.
</span>
<a href="https://arxiv.org/abs/2308.09124"
   >E Hernandez, A Sen Sharma, T Haklay, K Meng, M Wattenberg, J Andreas, Y Belinkov,
   <span class="me">D Bau</span>.
   <em>Linearity of Relation Decoding in Transformer Language Models.</em>
   <nobr>ICLR 2024 (spotlight).</nobr></a>
</p>

<input class="collapse" type="checkbox">
<p>
<img src="finetuning.png" class="projpic">
<a href="http://finetuning.baulab.info/">Fine-Tuning Enhances Existing Mechanisms.</a>
 When you fine-tune an LLM, are you teaching it something new or
 exposing what it already knows?  In this work, we pin down the detailed
 structure of the mechanisms for an entity-tracking task using new
 patching techniques, revealing a pre-existing circuit when a
 capability emerges from fine-tuning.
<span class="more"></span>
<span class="extra">
 The paper applies path-patching causal mediation methods as
 used in <a href="https://arxiv.org/abs/2211.00593">Wang 2022 (IOI)</a>
 to identify the components for a circuit for entity
 tracking that emerges after fine-tuning. Interestingly, we find that
 the components already existed in the model prior to fine-tuning.
 Furthermore we use
 <a href="https://dcm.baulab.info/">our DCM patching method</a>
 to deduce the type of information being transmitted at
 most of the steps before and after fine-tuning, and find that
 the role of the information is unchanged under fine-tuning.
 Finally, we introduce Cross-Model Activation Patching (CMAP) to
 test whether the encoding of information is changed after fine-tuning,
 and we find that the encodings are compatible, not only allowing
 interchange, but also revealing that improved task performance
 can be obtained by directly patching model activations between models.
</span>
<a href="https://arxiv.org/abs/2402.14811"
   >N Prakash, T R Shaham, T Haklay, Y Belinkov, <span class="me">D Bau</span>.
   <em>Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking.</em>
   <nobr>ICLR 2024.</nobr></a>
</p>

<input class="collapse" type="checkbox">
<p>
<img src="fv-thumb.png" class="projpic">
<a href="http://functions.baulab.info/">Function Vectors in Large Language Models.</a>
  The idea of treating a function reference as data is one of the most powerful
  concepts in computer science, enabling complex computational forms.
  Do neural networks learn to represent functions as data?
  In this paper, we study in-context-learning inside large transformer
  language models and show evidence that vector representations of
  functions appear.
<span class="more"></span>
<span class="extra">
  Function vectors (FVs) emerge when a language model generalizes
  a list of demonstrations of input-output pairs (via in-context
  learning, ICL).  To study how ICL works, we apply
  causal mediation analysis to identify attention heads
  that transport information that determines the task to execute.
  This analysis reveals a small number of attention heads that transport
  a vector which we call a <em>function vector</em> (FV), that
  generically encodes the task. We study the properties of FVs,
  finding that they can trigger execution of the function when
  injected into very different contexts including natural text.
  We find that FVs seem to directly encode the word embeddings
  of the output space, and that they also trigger nontrivial
  transformer calculations that differ from word-vector arithmetic.
  FVs are able to obey semantic vector algebra, but rather than
  operating on word embeddings, they enable compositions of
  function execution.
</span>
<a href="https://arxiv.org/abs/2310.15213"
   >E Todd, M L Li, A Sen Sharma, A Mueller, B C Wallace, <span class="me">D Bau</span>.
   <em>Function Vectors in Large Language Models.</em>
   <nobr>ICLR 2024.</nobr></a>
</p>

<input class="collapse" type="checkbox">
<p>
<img src="unified.png" class="projpic">
<a href="http://unified.baulab.info/">Unified Concept Editing in Diffusion Models.</a>
  Text-to-image diffusion models such as Stable Diffusion have many issues
  that limit their suitability for real-world deployment: they amplify racial and
  gender biases; they imitate copyrighted images; and they generate offensive content.
  We introduce a method, Unified Concept Editing, that allows precise editing of many
  concepts within a diffusion model, and we show that it can be used to reduce bias,
  copyright, and offensive content issues simultaneously.
<span class="more"></span>
<span class="extra">
  Our UCE method is a generalization and improvement upon the
  <a href="//rome.baulab.info/">ROME</a>,
  <a href="//memit.baulab.info/">MEMIT</a>, and
  <a href="https://time-diffusion.github.io/">TIME</a> methods.  It
  modifies the associations between textual concepts and visual concepts by
  directly editing the cross-attention parameters in the diffusion model
  without any additional training images.  Its closed-form parameter modification
  explicitly applies an optimal change to sets of concepts while protecting
  other sets of concepts from unintended modification.  The paper compares UCE
  to previous state-of-the-art erasure, debiasing, and offensive image removal
  methods and shows that our unified editing method outperforms previous separate
  approaches by a significant margin.
</span>
<a href="https://arxiv.org/abs/2308.14761"
   >R Gandikota, H Orad, Y Belinkov, J Materzy&nacute;ska, <span class="me">D Bau</span>.
   <em>Unified Concept Editing in Diffusion Models.</em> WACV 2024.</a>
</p>

<input class="collapse" type="checkbox">
<p>
<img src="futurelens.png" class="projpic">
<a href="http://future.baulab.info/">Future Lens.</a>
 Autoregressive language models like GPT are trained to
 predict the next word.  But we found they are also often thinking
 several further tokens ahead!  In this work, we measure this
 future information, and we show how to extend the
 <a href="https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens"
   >logit lens</a>
 to reveal a run of future anticipated tokens from individual transformer
 hidden states.
<span class="more"></span>
<span class="extra">
 Our paper experiments with several ways to decode future tokens from a
 single hidden state.  Inspired by "tuned lens" methods from
 <a href="https://arxiv.org/abs/2303.08112">Belrose</a> and
 <a href="https://arxiv.org/abs/2303.09435">Yom Din</a> that
 skip to future <em>layers</em>, we first try training a simple
 linear readout model. We also try transplanting the hidden state
 into the context of a prompt specially chosen to evoke future output.
 Using a <a href="https://aclanthology.org/2021.acl-long.353/">tuned prompt</a>
 reveals that two-ahead tokens can be predicted with more than 48% accuracy,
 which is good enough to be useful for "future lens" visualizations.
</span>
<a href="https://arxiv.org/abs/2311.04897"
   >K Pal, J Sun, A Yuan, B C Wallace, <span class="me">D Bau</span>.
   <em>Future Lens: Anticipating Subsequent Tokens from a Single Hidden State.</em>
   CoNLL 2023.
   </a>
</p>

<input class="collapse" type="checkbox">
<p>
<img src="erasing.png" class="projpic">
<a href="http://erasing.baulab.info/">Erasing Concepts from Diffusion Models.</a>
  We propose a method for fine-tuning model weights to erase concepts from
  diffusion models using their own knowledge. Given just the text of the concept
  to be erased, our method can edit the model weights to erase the concept while
  minimizing the inteference with other concepts. This type of fine-tuning has
  an advantage over previous methods: it is not easy to circumvent because it
  modifies weights, yet it is fast and practical because it avoids the expense
  of retraining the whole model on filtered training data.
<span class="more"></span>
<span class="extra">
  The ESD method erases a concept by using the original model's own
  knowledge of the concept as a guide while training a modified model.
  Rather than guiding the new model to imitate the original exactly, the new model
  is guided to imitate the original, while reversing its behavior of the selected
  concept.
  This objective corresponds to an exact ratio of probability distributions,
  and is straightforward to compute, equivalent to an application of
  <a href="https://arxiv.org/abs/2207.12598">classifier-free guidance</a>
  for training rather than inference. Our paper studies the ESD method
  as used to tune different sets of parameters, and as
  applied to a variety of concept-erasure applications including artistic style
  removal, offensive-image removal, and removing knowledge of object classes.
</span>
<a href="https://arxiv.org/abs/2303.07345"
   >R Gandikota, J Materzy&nacute;ska, Jaden Fiotto-Kaufman, <span class="me">D Bau</span>.
   <em>Erasing Concepts from Diffusion Models.</em> ICCV 2023.</a>
</p>
<input class="collapse" type="checkbox">
<p>
<img src="rome-animation.gif" class="projpic">
<a href="http://rome.baulab.info/">Locating and Editing Factual Associations in GPT.</a>
  In this project, we show that factual knowledge within GPT also corresponds to
  a <b>localized computation that can be directly edited</b>. For example, we can make a
  small change to a small set of the weights of GPT-J to teach it the counterfactual
  "Eiffel Tower is located in the city of Rome." Rather than merely regurgitating the new
  sentance, it will generalize that specific counterfactual knowledge and apply it in
  very different linguistic contexts.
<span class="more"></span>
<span class="extra">
  To show that factual knowledge within a GPT model corresponds to a simple, localized,
  and directly editable computation, we introduce three new concepts.
  (1) We introduce Causal Tracing, a method to locate decisive information within
  a network by corrupting and restoring hidden neural states; traces reveal how
  information about a fact is retrieved by MLP layers in the network.
  (2) We show how to apply rank-one matrix edits (ROME) to
  change individual memories within an MLP module within a transformer.
  (3) And we show how to distinguish between generalized factual knowledge and rote
  regurgitation of a fact, using a new data set called CounterFact.
</span>
<a href="https://arxiv.org/abs/2202.05262"
>K Meng* and <span class="me">D Bau*</span>, A Andonian, Y Belinkov.
<em>Locating and Editing Factual Associations in GPT</em>.
NeurIPS 2022.</a>
</p>

<input class="collapse" type="checkbox">
<p>
<img src="rewriting.gif" class="projpic">
<a href="http://rewriting.csail.mit.edu/">Rewriting a Deep Generative Model.</a>
  Deep network training is a blind optimization procedure
  where programmers define objectives but not the solutions that emerge.
  In this paper we ask if deep networks can be created in different way:
  we ask if a user can directly rewrite the rules of a model.
<span class="more"></span>
<span class="extra">
  We develop a method and a
  user interface that allows simple visual editing of the rules of
  a GAN, and demonstrate direct editing of high-level rules in pretrained
  state-of-the-art StyleGANv2 models.  Our method finds connections
  between modern large network layers and the classic neural data structure
  of Optimal Linear Associative Memory, and shows that it is feasible
  for a person to directly edit the weights of a large model to change
  its behavior, without training againist a data set, by understanding
  the model's internal structure.
</span>
<a href="http://rewriting.csail.mit.edu/paper/"
><span class="me">D Bau</span>, S Liu, TZ Wang, JY Zhu, A Torralba.
<em>Rewriting a Deep Generative Model</em>.
ECCV 2020 oral</a>.
</p>

<input class="collapse" type="checkbox">
<p>
<img src="individualunits.png" class="projpic">
<a href="http://dissect.csail.mit.edu/"
  >Understanding the Role of Individual Units in a Deep Neural Network.</a>
The causal role of individual units within a deep network can be
measured by directly changing those units and observing the impact.
<span class="more"></span>
<span class="extra">
  In this study, we unify and extend the netdissect and gandissect methods
  to compare and understand classifiers and generators.  Removing sets of
  units from a classifier reveals a sparse computational structure:
  we find that a small set of neurons is important
  for the accuracy of an individual classifier output class, and
  that neurons that are important for more classes also are more
  human-interpretable.
</span>
<a href="https://doi.org/10.1073/pnas.1907375117"
   ><span class="me">D Bau</span>, JY Zhu, H Strobelt, A Lapedriza,
   B Zhou, A Torralba. <em>Understanding the Role of Individual Units in
   a Deep Neural Network.</em>
   Proceedings of the National Academy of Sciences. 2020</a>.
</p>

<input class="collapse" type="checkbox">
<p>
<img src="sidn-thumb.png" class="projpic">
<a href="http://sidn.csail.mit.edu/"
  >Structure and Interpretation of Deep Networks.</a>
Most introductory courses on deep networks focus on how to train models, but it
is just as important to understand the structure and behavior of the models
after training is done.  By bringing current research in deep network
interpretation
to students, the SIDN course is designed to start filling that gap.
<span class="more"></span>
<span class="extra">
Organized with <a href="http://www.cs.technion.ac.il/~belinkov/"
>Yonatan Belinkov</a>,
<a href="https://juliusadebayo.com/about"
>Julius Adebayo</a>
and a group of a dozen brilliant speakers,
our course covered salience methods, global model analysis,
adversarial robustness, fairness, interactive methods, and natural
language explanations.  Each topic is anchored by a set of
hands-on exercises in Colab notebooks that are posted
online for students to work through and explore.
</span>
<a href="http://sidn.csail.mit.edu/">Organizers <b>D Bau</b>,
Y Belinkov, J Adebayo, H Strobelt, A Ross, V Petsiuk, S Gehrmann, M Suzgun,
S Santurkar, D Tsipras, I Chen, J Mu, J Andreas.
<em>Structure and Interpretation of Deep Networks.</em>
2020 IAP Course at MIT.</a>
</p>

<input class="collapse" type="checkbox">
<p>
<img src="seeing.png" class="projpic">
<a href="http://gandissect.csail.mit.edu/papers/Seeing_What_a_GAN_Cannot_Generate.pdf">Seeing what a GAN Cannot Generate</a>
studies mode dropping by asking the inverse question:
how can we decompose and understand what a GAN <em>cannot</em> do?
<span class="more"></span>
<span class="extra">A core challenge faced by GANs is <em>mode dropping</em>
or <em>mode collapse</em>, which is the tendendency for a GAN generator to
focus on a few modes and omit other parts of the distribution.
State-of-the-art GANs apply training methods designed to reduce
mode collapse, but analyzing the phenomenon remains difficult for large
distributions: examination of output samples reveals what a GAN <em>can</em>
do, not what it <em>cannot</em> do.  So in this paper we
develop a pair of complementary methods for decomposing what GAN omits,
looking at segmentation statistics over a distribution, and also visualizing
omissions in specific instances by calculating inversions of a GAN generator.
Surprisingly, we find that a state-of-the-art GAN will sometimes cleanly
omit whole classes of objects from its output, hiding these omissions
by creating realistic instances without those objects.
</span>
<a href="http://gandissect.csail.mit.edu/papers/Seeing_What_a_GAN_Cannot_Generate.pdf"
><span class="me">D Bau</span>, JY Zhu, J Wulff, W Peebles, H Strobelt,
B Zhou, A Torralba. <em>Seeing What a GAN Cannot Generate</em>.
ICCV 2019 oral</a>.
</p>

<input class="collapse" type="checkbox">
<p>
<img src="parliament.gif" class="projpic">
<a href="http://ganpaint.io/">
GAN Paint</a>
applies <a href="http://gandissect.csail.mit.edu/">
GAN dissection</a> to the manipulation of user-provided real
photographs.  By encoding a scene into a representation that can
be rendered by a generator network derived from a GAN, a user
can manipulate photo semantics, painting objects such as doors,
windows, trees,
and domes.  The details of rendering objects in plausible
configurations is left to the network.
<span class="more"></span>
<span class="extra">
Our previous GAN dissection work showed how to manipulate random
synthetic images generated by an unconditional GAN.  To manipulate
a real photograph <em>X</em> instead,
the generator must be guided to reproduce the photograph faithfully.
While <a href="https://github.com/junyanz/iGAN">previous work</a>
has investigated finding the best input <em>z</em>
so that <em>G(z)&asymp;X</em>, we show that it is useful to also optimize
the parameters of <em>G</em> itself.  Even in cases where the GAN is not
capable of rendering the details of the user-provided photo, a nearby
GAN generator can be found that does. We
implemented our algorithm using an interactive painting app at
<a href="http://ganpaint.io/">ganpaint.io</a>.
</span>
<a href="https://dl.acm.org/citation.cfm?id=3323023"
><span class="me">D Bau</span>, H Strobelt, W Peebles, J Wulff, B Zhou,
JY Zhu, A Torralba. <em>Semantic Photo Manipulation
  with a Generative Image Prior</em>.
  In SIGGRAPH 2019</a>.
</p>
<input class="collapse" type="checkbox">
<input class="collapse" type="checkbox">
<p>
<img src="gandissect.png" class="projpic">
<a href="http://gandissect.csail.mit.edu/">
GAN Dissection</a>
investigates the internals of a GAN, and shows how neurons can be
<a href="http://gandissect.res.ibm.com/ganpaint.html">directly manipulated</a>
to change the behavior of a generator.
<span class="more"></span>
<span class="extra">
Here we ask whether the apparent
structure that we found in classifiers also appears in a setting with
no supervision from labels.  Strikingly, we find that a state-of-the-art
GAN trained to generate complex scenes will learn neurons that are
specific to types of objects in the scene, such as neurons for trees,
doors, windows, and rooftops.
The work shows how to find such neurons, and shows that by forcing
the neurons on and off, you can cause a generator to draw or remove
specific types of objects in a scene.
</span>
<a href="https://openreview.net/pdf?id=Hyg_X2C5FX"
><span class="me">D Bau</span>, JY Zhu, H Strobelt, B Zhou, JB Tenenbaum,
WT Freeman, A Torralba. <em>GAN Dissection:
  Visualizing and Understanding Generative Adversarial Networks</em>.
  In ICLR 2019</a>.
</p>
<input class="collapse" type="checkbox">
<p>
<img src="netdissect.png" class="projpic">
<a href="http://netdissect.csail.mit.edu/">
Network Dissection</a>
is a technique for quantifying and automatically
estimating the human interpretability (and interpretation) of units
within any deep neural network for vision.
<span class="more"></span>
<span class="extra">
Building upon a surprising
<a href="https://arxiv.org/abs/1412.6856">2014 finding by Bolei Zhou</a>,
network dissection defines a dictionary of 1197 human-labeled
visual concepts, each represented as a segmentation problem, then
it estimates interpretability by evaluating each hidden convolutional
unit as a solution to those problems.
I have used network dissection to reveal that representation space is
not isotropic: learned representations have an unusually high agreement
with human-labeled concepts that vanishes under a change in basis.
We gave an oral presentation about
the technique and the insights it provides at CVPR 2017.
</span>
<a href="http://netdissect.csail.mit.edu/final-network-dissection.pdf"
><span class="me">D Bau</span>, B Zhou, A Khosla, A Oliva, and A Torralba. <em>Network Dissection:
Quantifying the Intepretability of Deep Visual Representations.</em>
CVPR 2017 oral</a>.
</p>
<input class="collapse" type="checkbox">
<p>
<img src="bbchunking.png" class="projpic">
<a href="http://cs.wellesley.edu/~blocks-and-beyond/1/">
Blocks and Beyond</a>
is a workshop I helped organize to bring together researchers who are
investigating blocked-based interfaces to simplify programming for
novices and casual programmers.
<span class="more"></span>
<span class="extra"> The workshop was oversubscribed, and the presented
work was interesting both for its breadth and depth.  Afterwards, we
wrote a review paper to survey the history, foundations, and
state-of-the-art in the field.
The review appears in the June 2017 Communications of the ACM; <a href="https://vimeo.com/216045469">also see the video overview</a>.</span>
<a href="http://dl.acm.org/authorize?N38021" title="Learnable programming: blocks and beyond"><span class="me">D Bau</span>, J Gray, C Kelleher, J Sheldon, F Turbak. <em>Learnable Programming: Blocks and Beyond.</em> Communications of the ACM, pp. 72-80. June 2017</a>.</p>
<input class="collapse" type="checkbox">
<p>
<img src="pencilgym.png" class="projpic">
<a href="https://pencilcode.net">
Pencil Code</a> is an open-source
project that makes it easier for novice programmers to work with
professional programming languages.
<span class="more"></span>
<span class="extra">Developed together with my son and with the generous
support of Google, this system provides a blocks-based editing environment
with turtle graphics on a canvas that smoothly transitions to text-based
editing of web applications using jQuery. Two thousand students use the
system each day. A study of middle-school
students using the environment suggests suggests the block-and-text
transitions are an aid to learning.</span>
<a href="http://dl.acm.org/authorize?N38022"><span class="me">D Bau</span>, D A Bau, M Dawson, C S Pickens. <em>Pencil code: block code for a text world.</em> In Proceedings of the 14th International Conference on Interaction Design and Children, pp. 445-448. ACM, 2015.</a>
</p>
<input class="collapse" type="checkbox">
<p>
<img src="freshimage.png" class="projpic">
<a href="https://images.google.com/">
Google Image Search</a> is the world's largest searchable index of images.
<span class="more"></span>
<span class="extra">I contributed several improvements to this product, including improved <a href="https://search.googleblog.com/2011/12/search-quality-highlights-new-monthly.html">ranking for recent images</a>, a <a href="https://googlesystem.blogspot.com/2013/06/new-ui-for-related-searches-in-google.html#gsc.tab=0">clustered broswing interface for discovering images</a> using related searches, a rollout of new serving infrastructure to support <a href="https://googleblog.blogspot.com/2010/07/ooh-ahh-google-images-presents-nicer.html">a long-scrolling result page</a>
 serving one thousand image results at a time, and improvements in the understanding of person entities on the web.</span>
<a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.722.1005">M Zhao, J Yagnik, H Adam, <span class="me">D Bau</span>, Large scale learning and recognition of faces in web videos. In Automatic Face & Gesture Recognition, 2008. FG'08. 8th IEEE International Conference on (pp. 1-7). IEEE, September 2008.</a>
</p>
<input class="collapse" type="checkbox">
<p>
<img src="gmailchat.png" class="projpic">
<a href="https://en.wikipedia.org/wiki/Google_Talk">
Google Talk</a>
is a web-based chat solution that was built-in to GMail.
<span class="more"></span>
<span class="extra">I led the team to create Google Talk in an (ultimately unsuccessful) attempt to establish a universal federated open realtime communication ecosystem for the internet.  Our messaging platform provided full-scale support for XMPP and Jingle, which are open standards for federating real-time chat and voice that are analogous to the open-for-all SMTP system for email. When these open protocols came under asymmetric attack by Microsoft (they provided only one-way compatibility), Google relented and reverted to a closed network. To this day, open realtime communications remains an unfulfilled dream for the internet.</span>
<a href="https://googleblog.blogspot.com/2005/08/google-gets-to-talking.html"><span class="me">D Bau</span>. <em>Google Gets to Talking</em>. Google Official Blog, August 2005.</a>
</p>
<input class="collapse" type="checkbox">
<p>
<img src="xmlbeans.png" class="projpic">
<a href="https://en.wikipedia.org/wiki/XMLBeans">
Apache XML Beans</a> is an open-source implementation of the XML Schema specification as a compiler from schema types to Java classes.
<span class="more"></span>
<span class="extra">Still used as a powerful document interchange technology, my team's implementation of this standard is a good example of an important approach that continues to be a key technique for the creation of understandably complex systems: the prioritization of faithful and transparent data representations over simplified but opaque functional encapsulations.</span>
<a href="http://davidbau.com/archives/2003/11/14/the_design_of_xmlbeans_part_1.html"><span class="me">D Bau</span>. <em>The Design of XML Beans</em>, davidbau.com, a dabbler's weblog, November 2003.</a>
</p>
<input class="collapse" type="checkbox">
<p>
<img src="ie4logo.png" class="projpic">
<a href="https://en.wikipedia.org/wiki/Internet_Explorer_4">
Microsoft Internet Explorer 4</a> was the first AJAX web browser.
<span class="more"></span>
<span class="extra">As part of the <a href="https://en.wikipedia.org/wiki/Trident_(layout_engine)">Trident</a> team led by <a href="https://en.wikipedia.org/wiki/Adam_Bosworth">Adam Bosworth</a>, I helped create the first fully mutable HTML DOM by defining its asynchronous loading model. My contribution was to implement an incremental HTML parser that uses speculative lookahead to drive a fast multithreaded preloader for linked resources, while maintaining a consistent view of programmable elements for single-threaded scripts that can change the document during loading.</span>
The design of the system resolved tensions between performance, flexiblity, and programmability, and contributed to the strength of the modern web platform.</p>
<input class="collapse" type="checkbox">
<p>
<img src="linalg.png" class="projpic">
<a href="http://people.maths.ox.ac.uk/~trefethen/text.html">
Numerical Linear Algebra</a> is the graduate textbook on numerical linear algebra I wrote with my advisor <a href="http://people.maths.ox.ac.uk/~trefethen/">Nick Trefethen</a> while earning a Masters at Cornell.
<span class="more"></span>
<span class="extra">The book began as a detailed set of notes that I took while attending Nick's course. The writing is intended to capture the spirit of his teaching: succinct and insightful.  The hope is to reveal the elegance of this family of fundamental algorithms and dispel the myth that finite-precision arithmetic means imprecise thinking.</span>
<a href="https://scholar.google.com/scholar?cluster=4058884683459283601">L N Trefethen, <span class="me">D Bau</span>. Numerical linear algebra. Vol. 50. Siam, 1997.</a></p>
</div> <!-- publication -->
</div>
</div>

<div class="row">
<div class="col">
<div class="footer">
        <a href="https://baulab.info/">Home</a>
        <a href="http://dblp.uni-trier.de/pers/hd/b/Bau:David">Dblp</a>
        <a href="https://scholar.google.com/citations?hl=en&user=CYI6cKgAAAAJ&view_op=list_works&sortby=pubdate">Scholar</a>
        <a href="https://github.com/davidbau">Github</a>
        <a href="https://www.linkedin.com/in/david-bau-4b8130/">LinkedIn</a>
        <a rel="me" href="https://sigmoid.social/@davidbau">Mastodon</a>
        <a href="http://davidbau.com">Personal Blog</a>
        <a href='https://www.google.com/search?safe=off&noj=1&biw=1855&bih=917&q=david+bau+-mp3+-radio+-soundcloud+-minnesota+-tennis+-mx+-romero+-techno+-remix+-spotify+-pandora+-"noah+david"+-"extension+educator"+-"bau+mann"+-"bau+man"+-"bau+mert"+-"bau+telle"+-"bau+xi"+-"behavioural analysis"+-mirador&oq=david+bau+-music+-mp3+-radio+-youtube+-soundcloud+-minnesota+-tennis+-"records"+-"noah+david"+-"extension+educator"+-Noguer+-dgbau+-worthington+-"bau+mann"+-"bau+man"+-"bau+telle"+-"bau+xi"+-mirador+-gmbh'>Search</a>
</div>
</div>
</div>

</div>
<script>
// Redirect to new location.
if (window.location.host == 'people.csail.mit.edu' ||
    window.location.host == 'davidbau.com') {
  window.location.replace('https://baulab.info/');
}
</script>
<script>
$(document).on('click', '.more, .publication p', function(ev) {
  // Do not collapse a card if the click is for a hyperlink or selection.
  if ($(ev.target).closest('a').length ||
          getSelection().type == 'Range' || ev.shiftKey || ev.ctrlKey) {
    return;
  }
  // Use the hidden checkbox technique to preserve collapse-state on "back"
  var collapse = $(this).closest('p').prev('input.collapse');
  collapse.prop('checked', !collapse.prop('checked'));
  ev.stopPropagation();
});
</script>
</body>
<script type="text/javascript">
  var player;
  function onYouTubeIframeAPIReady() {
    player = new YT.Player('selfpic-video', { events: {
     'onStateChange': function() {
        player.setOption('captions', 'fontSize', 2);
      },
    }});
  }
</script>
<script src="https://www.youtube.com/iframe_api"></script>
</html>
